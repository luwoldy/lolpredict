{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>champLevel</th>\n",
       "      <th>creeps_early</th>\n",
       "      <th>creeps_end</th>\n",
       "      <th>creeps_late</th>\n",
       "      <th>creeps_mid</th>\n",
       "      <th>csdiff_early</th>\n",
       "      <th>csdiff_end</th>\n",
       "      <th>csdiff_late</th>\n",
       "      <th>csdiff_mid</th>\n",
       "      <th>...</th>\n",
       "      <th>wardsPlaced</th>\n",
       "      <th>win</th>\n",
       "      <th>xp_early</th>\n",
       "      <th>xp_end</th>\n",
       "      <th>xp_late</th>\n",
       "      <th>xp_mid</th>\n",
       "      <th>xpdiff_early</th>\n",
       "      <th>xpdiff_end</th>\n",
       "      <th>xpdiff_late</th>\n",
       "      <th>xpdiff_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>285.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.1</td>\n",
       "      <td>263.0</td>\n",
       "      <td>-17.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.7</td>\n",
       "      <td>-116.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>265.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.2</td>\n",
       "      <td>478.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>294.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>515.7</td>\n",
       "      <td>442.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.70</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.8</td>\n",
       "      <td>630.0</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373.6</td>\n",
       "      <td>190.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>262.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.7</td>\n",
       "      <td>-78.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-179.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   assists  champLevel  creeps_early  creeps_end  creeps_late  creeps_mid  \\\n",
       "0       12          14           0.6         0.0          1.6         1.0   \n",
       "1        3          15           0.2         0.0          1.3         0.2   \n",
       "2       10          15           2.7         0.0          6.0         6.5   \n",
       "3        4          17           7.3         0.0          7.2         8.0   \n",
       "4        4          10           1.3         0.0          0.0         1.9   \n",
       "\n",
       "   csdiff_early  csdiff_end  csdiff_late  csdiff_mid     ...      wardsPlaced  \\\n",
       "0         -1.25         0.0         -1.1       -1.05     ...               18   \n",
       "1          0.00         0.0          0.0        0.00     ...                6   \n",
       "2          0.00         0.0          0.0        0.00     ...                9   \n",
       "3          2.20         0.0          5.2        4.70     ...                6   \n",
       "4         -0.35         0.0          0.0       -0.85     ...                7   \n",
       "\n",
       "   win  xp_early  xp_end  xp_late  xp_mid  xpdiff_early  xpdiff_end  \\\n",
       "0    1     285.8     0.0    560.1   263.0        -17.85         0.0   \n",
       "1    1     265.2     0.0    635.2   478.0          0.00         0.0   \n",
       "2    1     294.5     0.0    515.7   442.7          0.00         0.0   \n",
       "3    1     523.0     0.0    594.8   630.0         71.00         0.0   \n",
       "4    0     262.5     0.0      0.0   240.7        -78.30         0.0   \n",
       "\n",
       "   xpdiff_late  xpdiff_mid  \n",
       "0         44.7     -116.45  \n",
       "1          0.0        0.00  \n",
       "2          0.0        0.00  \n",
       "3        373.6      190.10  \n",
       "4          0.0     -179.35  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull in the data\n",
    "\n",
    "url = \"final.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.fillna(0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the target\n",
    "\n",
    "target = df[\"highest_tier\"]\n",
    "# target_names = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>champLevel</th>\n",
       "      <th>creeps_early</th>\n",
       "      <th>creeps_end</th>\n",
       "      <th>creeps_late</th>\n",
       "      <th>creeps_mid</th>\n",
       "      <th>csdiff_early</th>\n",
       "      <th>csdiff_end</th>\n",
       "      <th>csdiff_late</th>\n",
       "      <th>csdiff_mid</th>\n",
       "      <th>...</th>\n",
       "      <th>wardsPlaced</th>\n",
       "      <th>win</th>\n",
       "      <th>xp_early</th>\n",
       "      <th>xp_end</th>\n",
       "      <th>xp_late</th>\n",
       "      <th>xp_mid</th>\n",
       "      <th>xpdiff_early</th>\n",
       "      <th>xpdiff_end</th>\n",
       "      <th>xpdiff_late</th>\n",
       "      <th>xpdiff_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>285.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.1</td>\n",
       "      <td>263.0</td>\n",
       "      <td>-17.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.7</td>\n",
       "      <td>-116.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>265.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.2</td>\n",
       "      <td>478.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>294.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>515.7</td>\n",
       "      <td>442.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.70</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.8</td>\n",
       "      <td>630.0</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373.6</td>\n",
       "      <td>190.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>262.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.7</td>\n",
       "      <td>-78.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-179.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   assists  champLevel  creeps_early  creeps_end  creeps_late  creeps_mid  \\\n",
       "0       12          14           0.6         0.0          1.6         1.0   \n",
       "1        3          15           0.2         0.0          1.3         0.2   \n",
       "2       10          15           2.7         0.0          6.0         6.5   \n",
       "3        4          17           7.3         0.0          7.2         8.0   \n",
       "4        4          10           1.3         0.0          0.0         1.9   \n",
       "\n",
       "   csdiff_early  csdiff_end  csdiff_late  csdiff_mid     ...      wardsPlaced  \\\n",
       "0         -1.25         0.0         -1.1       -1.05     ...               18   \n",
       "1          0.00         0.0          0.0        0.00     ...                6   \n",
       "2          0.00         0.0          0.0        0.00     ...                9   \n",
       "3          2.20         0.0          5.2        4.70     ...                6   \n",
       "4         -0.35         0.0          0.0       -0.85     ...                7   \n",
       "\n",
       "   win  xp_early  xp_end  xp_late  xp_mid  xpdiff_early  xpdiff_end  \\\n",
       "0    1     285.8     0.0    560.1   263.0        -17.85         0.0   \n",
       "1    1     265.2     0.0    635.2   478.0          0.00         0.0   \n",
       "2    1     294.5     0.0    515.7   442.7          0.00         0.0   \n",
       "3    1     523.0     0.0    594.8   630.0         71.00         0.0   \n",
       "4    0     262.5     0.0      0.0   240.7        -78.30         0.0   \n",
       "\n",
       "   xpdiff_late  xpdiff_mid  \n",
       "0         44.7     -116.45  \n",
       "1          0.0        0.00  \n",
       "2          0.0        0.00  \n",
       "3        373.6      190.10  \n",
       "4          0.0     -179.35  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the outcomes and a couple of other unwanted variables\n",
    "\n",
    "\n",
    "\n",
    "data = df.drop(\"highest_tier\", axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the meaning of life\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.582/0.418\n",
      "k: 3, Train/Test Score: 0.698/0.328/0.370\n",
      "k: 5, Train/Test Score: 0.543/0.306/0.237\n",
      "k: 7, Train/Test Score: 0.478/0.295/0.184\n",
      "k: 9, Train/Test Score: 0.448/0.298/0.150\n",
      "k: 11, Train/Test Score: 0.424/0.298/0.125\n",
      "k: 13, Train/Test Score: 0.404/0.297/0.106\n",
      "k: 15, Train/Test Score: 0.397/0.300/0.096\n",
      "k: 17, Train/Test Score: 0.386/0.301/0.085\n",
      "k: 19, Train/Test Score: 0.378/0.299/0.079\n",
      "k: 21, Train/Test Score: 0.373/0.298/0.075\n",
      "k: 23, Train/Test Score: 0.367/0.299/0.068\n",
      "k: 25, Train/Test Score: 0.360/0.303/0.058\n",
      "k: 27, Train/Test Score: 0.360/0.306/0.054\n",
      "k: 29, Train/Test Score: 0.357/0.304/0.053\n",
      "k: 31, Train/Test Score: 0.354/0.305/0.049\n",
      "k: 33, Train/Test Score: 0.352/0.302/0.050\n",
      "k: 35, Train/Test Score: 0.351/0.301/0.050\n",
      "k: 37, Train/Test Score: 0.348/0.302/0.046\n",
      "k: 39, Train/Test Score: 0.345/0.302/0.044\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8XHW5+PHPk8neJE2XtM3WDUppitCNFihWQISCWhDwAl5QFuGicv25ALZcRC56LygoKCJeRBYFQTYBAalIgcoitHRfSOlC2ySlSZe0abMnz++Pc5JMppPkpMnMmck879frvGbOmbM8Pc2cZ77ne77fr6gqxhhjDECS3wEYY4yJHZYUjDHGtLOkYIwxpp0lBWOMMe0sKRhjjGlnScEYY0w7SwrGGGPaWVIwxhjTzpKCMcaYdsl+B9Bbw4cP17Fjx/odhjHGxJUPPvhgl6rm9bRe3CWFsWPHsnTpUr/DMMaYuCIiW72sZ7ePjDHGtLOkYIwxpp0lBWOMMe0sKRhjjGlnScEYY0y7iCUFEXlQRCpFZE0Xn4uI/EpENorIKhGZFqlYnltezuzbFzFu/kvMvn0Rzy0vj9ShjDEmrkWypPAwMLebz88CJrjT1cB9kQjiueXlLHh2NeXVdShQXl3HgmdXW2IwxpgwIpYUVHUxsKebVc4B/qCOfwG5IpLf33HcsbCUuqaWTsvqmlq4Y2Fpfx/KGGPinp91CoXA9qD5MnfZIUTkahFZKiJLq6qqenWQiuq6Xi03xphE5mdSkDDLNNyKqnq/qs5Q1Rl5eT220u6kIDejV8uNMSaR+ZkUyoDioPkioKK/D3L9mRPJSAl0WpaREuD6Myf296GMMSbu+ZkUXgC+6j6FdAKwT1V39PdBzp1ayG3nfYpCt2SQnpLEbed9inOnhr1TZYwxCS1iHeKJyOPAKcBwESkDfgSkAKjqb4GXgbOBjUAtcHmkYjl3aiHnTi3km499wNqK/ZYQjDGmCxFLCqp6cQ+fK/CtSB0/nMkFg3l59Sfsr28iJz0lmoc2xpi4kFAtmkvycwD4cEeNz5EYY0xsSqikMLnASQprK/b5HIkxxsSmhEoKedlpDM9KZV3Ffr9DMcaYmJRQSUFEmJSfw7odlhSMMSachEoK4FQ2b9hZQ2Nzq9+hGGNMzEm4pFBSkENTi7Kx8oDfoRhjTMxJuKRglc3GGNO1hEsKY4cNIiMlYPUKxhgTRsIlhUCSMCk/m7X2BJIxxhwi4ZICOPUK6yv24zSqNsYY0yYxk0L+YGoaminba2MqGGNMsIRMClbZbIwx4SVkUpg4KptAkljLZmOMCZGQSSE9JcAReYOsstkYY0IkZFIAp8dUeyzVGGM6S9ykUJDDjn317DnY6HcoxhgTMxI2KUwuGAxg9QrGGBMkYZNC24A763bYE0jGGNMmYZPCkEGpFAxOt8pmY4wJEtGkICJzRaRURDaKyPwwn48RkddEZJWIvCEiRZGMJ1RJQY7dPjLGmCARSwoiEgDuBc4CSoCLRaQkZLU7gT+o6rHArcBtkYonnJKCwWyqOkBdY0s0D2uMMTErkiWFmcBGVd2sqo3AE8A5IeuUAK+5718P83lEleTn0KpQurMmmoc1xpiYFcmkUAhsD5ovc5cFWwmc777/EpAtIsNCdyQiV4vIUhFZWlVV1W8BWncXxhjTWSSTgoRZFtot6XXAZ0RkOfAZoBxoPmQj1ftVdYaqzsjLy+u3AIuGZJCdnmz1CsYY40qO4L7LgOKg+SKgIngFVa0AzgMQkSzgfFWN2s92EbGWzcYYEySSJYUlwAQRGSciqcBFwAvBK4jIcBFpi2EB8GAE4wlrcsFgPtxRQ0urja1gjDERSwqq2gxcCywE1gNPqupaEblVROa5q50ClIrIBmAk8D+RiqcrJQU51DW1sGXXwWgf2hhjYk4kbx+hqi8DL4csuzno/dPA05GMoSdtLZvXVuzjyBFZfoZijDG+S9gWzW2OHJFFaiDJ6hWMMQZLCqQmJzFhZJY9gWSMMVhSAJz2Cusq9qNqlc3GmMRmSQGnXmH3wUYqaxr8DsUYY3xlSQGYXOiMrWAtm40xic6SAnD0qGzABtwxxhhLCkB2egpjhmXa2ArGmIRnScE1ucC6uzDGGEsKrpL8HLburmV/fZPfoRhjjG96TAoikiEiC0Tkt+78kSJyVuRDi67JBU5l84c7bGwFY0zi8lJSeBCnG+yT3fkK4H8jFpFPStyxFdbZE0jGmATmJSlMUNX/BZoAVLWW8GMlxLUR2WkMG5Rqlc3GmITmJSk0ikg67gA5IjIOaIxoVD4QEUqsstkYk+C8JIVbgVeAIhF5BGcs5QURjconJQU5bNhZQ2Nzq9+hGGOML7rtOltEBGcc5S8DJ+HcNrpeVSujEFvUTS4YTFOLsrHyQHsdgzHGJJJuSwrq9BD3oqpWqerzqvrcQE0I0HlsBWOMSURebh+9LyLTIh5JDBg3fBAZKQGrVzDGJCwvI6+dDFwlIpuAgzi3kFRVB1yiCCQJR+dnWx9IxpiE5SUpnBvxKGJISX4OL6ysQFVxqlSMMSZx9Hj7SFU3ARnA59wp3V3WIxGZKyKlIrJRROaH+Xy0iLwuIstFZJWInN3bf0B/m1wwmJr6Zsr21vkdijHGRJ2Xbi6uBZ4ERrvTkyLyTQ/bBYB7gbOAEuBiESkJWe0m4ElVnQpcBPymd+H3v7anjqyy2RiTiLxUNF8NzFTVG1X1RmAWcI2H7WYCG1V1s6o2Ak8A54Sso0Dbs5+DcbrQ8NXRo7JJEhtbwRiTmLwkBcHt4sLVhLduLgqB7UHzZe6yYLcAl4hIGfAy8J9hAxC5WkSWisjSqqoqD4c+fOkpAY7Iy7LuLowxCclLUvgj8C8RuUlEbgLeAR7xsF24xKEh8xcDD6tqEXA28EcROSQmVb1fVWeo6oy8vDwPh+4b6+7CGJOovFQ0/wznFlItUAdco6p3eth3GVAcNF/EobeHrsSpr0BV3wXSgeEe9h1Rkwty2LGvnj0HB1wXT8YY0y0vFc3HA+tV9Req+nPgQxGZ4WHfS4AJIjJORFJxKpJfCFlnG/BZ9ziTcJJCZO8PeVCS74ytYPUKxphE4+X20f04pYQ2B4H/62kjVW0GrgUWAutxnjJaKyK3isg8d7Xv4zSMWwk8Dlzmdq3hq/axFXbYE0jGmMTipfFakqq2dxuqqq0ikuJl56r6Mk4FcvCym4PerwNme4w1aoYOSiV/cLpVNhtjEo6XksIWEfmGiAREJElEvgV8HOG4fDe5IMduHxljEo6XpPAfOPf9dwKVwGeAqyIZVCwoyc9hU9UB6hpb/A7FGGOipsfbR6q6E7ggCrHElJKCHFoVSnfWMKU41+9wjDEmKrosKYjIFSJypPteROR+EdktIstEZEr0QvTH5AJ7AskYk3i6u330PWCr+/5C4HicPoxuBH4V4bh8VzQkg+z0ZOsDyRiTULpLCs2q2ta9xReBR1R1p6q+AmRFPjR/iQgl+day2RiTWLpLCioiI0UkDaei+R9Bn2VENqzYUFKQw4c7amhp9b3phDHGREV3SeEWYBmwGfibqq4BEJFPA1siH5r/SvJzqGtqYcuug36HYowxUdFlUlDV54FxwBRVvTzooxU4XVYMeG2VzVavYIxJFN22U1DVRlWtCllWo6oJcaP9yBFZpATE6hWMMQnDS+O1hJWanMRRI7PtsVRjTMKwpNCDknynu4sY6KfPGGMizkvX2U+IyJki4mW0tQFnckEOuw82UlnT4HcoxhgTcV5KCg8DVwAbROQnba2cE0WJVTYbYxKIl5HXXlHVC4GZwCfA6yKyWEQuFREvXW/HtUn52YB1d2GMSQye6hREZAjwFeBSYBXOIDsnAa9ELrTYkJ2ewphhmTa2gjEmIfT4S19EngQ+BfwJOF9Vy9yPHhOR5ZEMLlZYdxfGmETh5fbPA8Cr4YbJVNWp/R9S7JlckMPf1nxCTX0T2emeBp0zxpi45OX20XhgcNuMiAwRkasjF1LsaRuzef2OGp8jMcaYyPKSFK5R1eq2GVXdC3zDy85FZK6IlIrIRhGZH+bzu0RkhTttEJHqcPvxW0l+29gK9gSSMWZg85IUAsEzIpIE9HgPRUQCwL3AWTjjMFwsIiXB66jqd1V1iqpOAe4BnvUaeDS9u2kXSQK3/HUds29fxHPLy/0OyRhjIsJLUnhVRB4Xkc+IyBzgMTp3o92VmcBGVd2sqo3AE8A53ax/MfC4h/1G1XPLy7nxL2to6z27vLqOBc+utsRgjBmQvCSF64F3gO8C3wfeAq7zsF0hsD1ovsxddggRGYPTI+uiLj6/WkSWisjSqqqqcKtEzB0LS6lraum0rK6phTsWlkY1DmOMiYYenz5S1RacWzv39HLf4brF6KoDoYuAp91jhYvhfuB+gBkzZkS1E6KK6rpeLTfGmHjmpe+jI9z+j1a5lcEbRGSDh32XAcVB80VARRfrXkQM3joCKMgNP8hcV8uNMSaeee376CGcX/5nAU/i1A/0ZAkwQUTGiUgqzoX/hdCVRGQiMAR412PMUXX9mRPJSOlU1056ShLXnznRp4iMMSZyvCSFTFVdCKCqm1T1JuDUnjZS1WbgWmAhsB54UlXXisitIjIvaNWLgSfCNY6LBedOLeS28z5FYW5G+/2ws48ZxblTw1aPGGNMXPPSornB7TZ7k4hcA5QDI7zsXFVfBl4OWXZzyPwt3kL1z7lTC9uTwBfu+ScbKg/4HJExxkSGl5LCd4Es4NvAbODrOF1pJ6Tzphaxpnw/pZ9Y62ZjzMDTbVJwG6B9yR2XeZuqXqqq56jq21GKL+acM6WA5CTh2WVlPa9sjDFxptuk4D4iOjNKscSFYVlpnDJxBH9ZXk5zS6vf4RhjTL/ycvtomYg8KyIXi8i8tinikcWw86cVUlnTwNubdvsdijHG9CsvFc0jgYPA2UHLlDCPlyaK0yaNYHBGCs98UMZnjsrzOxxjjOk3Xlo0XxqNQOJJWnKALx6Xz1NLy2yMBWPMgOJl5LX7wy1X1YQaUyHU+dOKePRf23h59Q4uPH603+EYY0y/8FKn8FrQ9DZOG4WGSAYVD6YU5zI+bxDPfGC9pRpjBg4vt4/+HDwvIn8EXo1YRHFCRDh/WhF3LCxl2+5aRg/L9DskY4zpMy8lhVDjgDH9HUg8OndqISLw7HJrs2CMGRi89JK6V0T2uFM1TinhxsiHFvsKczM4cfwwnl1WTox23WSMMb3ipaQwHMhzpyGqOl5Vn4xsWPHj/GlFbNtTy9Kte/0OxRhj+sxLUvg8kKWqLaqqIpIrIl+IdGDxYu4xo8hMDVi3F8aYAcFLUrhVVfe1zahqNfDjyIUUXwalJTP3mFG8uHIH9U1hB44zxpi44SUphFvHS0vohHHBtCJqGpr5+7qdfodijDF94rXvo5+JyBgRGS0idwDLIx1YPDlh/DAKBqfbLSRjTNzzkhSuddd7Hqe/IwW+Gcmg4k1SkvClaYUs3lBF5f56v8MxxpjD1mNSUNUDqnqdqk5xpxtU1YYeC3HetCJaFZ5fUeF3KMYYc9i8tFN4RURyg+aHiMhLkQ0r/hyRl8WU4lyeWVZmbRaMMXHLy+2jke4TRwCo6l6gwMvORWSuiJSKyEYRmd/FOv8mIutEZK2I/Mlb2LHp/OlFfPhJDet27Pc7FGOMOSxekkKriBS1zYiIpy5B3aE87wXOAkqAi0WkJGSdCcACYLaqTga+4zXwWPTFY/NJDSRZJ3nGmLjlJSncDLwtIg+JyEPAYrx1czET2Kiqm1W1EXgCOCdknauAe93SB6pa6T302JObmcpnJ43g+RXlNNlQncaYOOSlovklnAt829NHM1X1bx72XQhsD5ovc5cFOwo4SkTeFpF/icjccDsSkatFZKmILK2qqvJwaP+cP62I3QcbWbwhtuM0xphwvPaSWg9sA3YCR4rISR62kTDLQmtgk4EJwCnAxcADwZXa7Rup3q+qM1R1Rl5ebA9/+ZmJeQwblMoz1mbBGBOHvDx9dAXwDrAI+Kn7+r8e9l0GFAfNFwGhz2uWAc+rapOqbgFKcZJE/3nrbtiyuPOyLYud5RGQEkhi3pQC/rGukn21TRE5hjHGRIqXksJ3gRnAx6r6aWA6sMPDdkuACSIyTkRSgYtwbj8Few44FUBEhuPcTtrsMXZvCqfBU5d1JIYti535wmn9ephg508rorGllb+usjYLxpj44iUp1KtqHYCIpKrqWuDonjZS1Wac1tALgfXAk6q6VkRuFZF57moLgd0isg54HbheVXcfzj+kS+PmwJcfhj9/FR7/ipMQvvywszxCJhfkMHFktnV7YYyJO146ttvh3uf/K7BQRPbg1C30SFVfBl4OWXZz0HsFvudOkTNuDuQfC6UvwQnXRjQhgDtU5/RC/vflD9lcdYDxeVkRPZ4xxvQXL08fzVPValX9IfAT4DEOfbQ0tm1ZDDtWOO+XP3JoHUMEnDulkCSBZ5dZmwVjTPzo1RjNqvqaqj6rqg2RCqjftdUhnP8gJKXAkWd0rmOIkBE56Xx6Qh5/WV5Oa6t1e2GMiQ+9SgpxqXyZU4cw4XTIPw5qdjjz5csifujzphVSXl3Hv7b0bzWJMcZEysBPCid/p6MOoXgWVCyD0Sc6yyPszMmjyE5LtltIxpi4MfCTQrDi46G5Hj5ZFZXDpacE+Pyx+fxt9Q5qG5ujckxjjOkLL43X9orInpBpi4g8JSJjIx9iPyqa6bxuXxK1Q543rYiDjS28suaTqB3TGGMOl5eSwj3AD4EjgCOBm4CHcRqePRSxyCJhcCEMLobt70XtkMePHULx0Ay7hWSMiQteksIZqnqvqu5V1T2q+hvgLFV9DBga4fj6X9HxsP39qB1ORCgZlcNbG3cxbv5LzL59Ec8ttwRhjIlNnuoUROS8kPdtnd3FX//QxbNgfxnsi86F+bnl5bzh9piqQHl1HQueXW2JwRgTk7wkhUuAq9y6hN04YyBcKiKZxOOgOMXHO69l0Skt3LGwlIbmzrmzrqmFOxaWRuX4xhjTGz12c6GqG3FGTwvnzf4NJwpGHQvJGc4tpMlfivjhKqrrerXcGGP81GNScHsvvQIYG7y+ql4dubAiKJDi9JAapXqFgtwMysMkgILcjKgc3xhjesPL7aPngZHAW8BrQVP8KjoedqyEpsj/Wr/+zIlkpAQOWT73mFERP7YxxvSWl15SB6nq9yMeSTQVz4K374aKFTDmxIge6typzgikdywspaK6jlGD00kOCI+9t5XPH5vPtNFDInp8Y4zpDS9J4W8icoaq/j3i0URLsduIrez9iCcFcBJDW3IA2HWggfPve4evP7KUZ75xEuOGD4p4DMYY44WX20fXAK+IyAH3CaS97pgK8WvQcBg6PqrtFYINz0rjkcudxHTZQ++z60D8dDprjBnYvCSF4UAKMBjIc+fzIhlUVBTPclo2qz/dWo8dPojff20GO/fXc+XDS6xvJGNMTOgyKYjIBPft5C6m+FY8Ew5Wwd6PfQth6ugh3HPxNFaX7+M//7Sc5pb4awtojBlYuispzHdf7w0z/TrCcUVee+d4/txCavO5kpHces4xvPZhJT98fi3qU8nFGGOgm6Sgqle6b09T1U8HT8BnvexcROaKSKmIbBSR+WE+v0xEqkRkhTt9/fD+GYdhxCRIzY5ay+buXHLCGL516hE8/v427n19o9/hGGMSmJenj94DpnlY1omIBHBKFZ8DyoAlIvKCqq4LWfXPqnqtx3j7T1IAiqZHtcfU7lx3xkR2VNdz5983MGpwBhdML/I7JGNMAuoyKYjICCAfyBCRT9HRCV4OkOlh3zOBjaq62d3fE8A5QGhS8E/xLFh8BzTUQFq2r6GICLeffyyVNQ3Mf2YVI3PS+PSE+K/PN8bEl+7qFD6PU3dQROf6hBtxxlfoSSGwPWi+zF0W6nwRWSUiT4tIcbgdicjVIrJURJZWVVV5OLRHxTNBW6MyXrMXqclJ3HfJNI4ckcU3Hl3G2op9fodkjEkw3dUpPOTWH1ypqnOC6hTOVtWnPOxbwiwLrUX9KzBWVY8F/gE80kUs96vqDFWdkZfXj7+eC2c4rz5XNgfLTk/hkStmkpOezOUPLaFsb63fIRljEoiXdgojRCQHQER+KyLvi4iXiuYyIPiXfxFQEbyCqu5W1baWW78DpnvYb//JyIW8STFTr9BmZE46D18xk/qmFi57aAnVtY1+h2SMSRBeksLVqrpfRM7AubB/A/iZh+2WABNEZJyIpAIXAS8EryAi+UGz84D13sLuR8UzoWwJtMZWG4GjRmZz/1dnsG13Lef95h1Ouu01G7nNGBNxXpJC2y2fs4CHVPUDL9upajNwLbAQ52L/pKquFZFbRWSeu9q3RWStiKwEvg1c1tt/QJ8Vz4T6atj9UdQP3ZMTxg/jopnFbN51kIp99TZymzEm4rw8krpSRF4GjgL+S0SyOLRuICxVfRl4OWTZzUHvFwALvIcbAcWznNft70HeRF9DCee19ZWHLGsbuS24kz1jjOkPXkoKlwO3ADNVtRZIB67sdot4MuxIyBgSU5XNwWzkNmNMNHm5DdQCjMepSwDI8LJd3BBxuryI0aTQ1QhtyQHhnU27ohyNMWag6/HiLiK/Bk4FLnEXHQR+G8mgoq54Juwqhbq9fkdyiHAjt6UEhMzUAF/53Xtc+vv3WFVW7VN0xpiBxssv/pNU9T+AegBV3QOkRjSqaGsfdGepv3GEce7UQm4771MU5mYgQGFuBndccBzv3Xg6N31+EmvK9zHv12/zzcc+YGPlAb/DNcbEOS8VzU0ikoRbuSwiw4DYen6zrwqmgQScyuYJn/M7mkOEjtzW5uufHs+FxxfzwD+38MA/N/PKmk+4YHoR/+/0oyjs4raTMcZ0p7vxFNoSxr3AM0CeiPw38Bbw0yjEFj1pWTDqmJitV+hOdnoK3/3cUSy+4VQuO2kczy2v4NQ73+DHL65jt43oZozpJemq/34RWaaq09z3k4HTcbqu+IeqroleiJ3NmDFDly6NwG2el66DlY/DD7ZCwEsBKjaV7a3ll//4iGeWlZGREuCqOeMZlZPOPYs2UlFdR0FuBtefOdEeZzUmwYjIB6o6o6f1urv6tfddpKprgbX9EVjMKp4FS34Hlesg/1i/ozlsRUMyuePLx/EfnxnPnQs3cPc/OjfKa2v8BlhiMMYcorukkCci3+vqQ1X9RQTi8U97ZfP7cZ0U2hw5IpvfXjqd43/yD6pCbiNZ4zdjTFe6e/ooAGQB2V1MA0vuaMgaGZf1Ct3Z1UW9Qnl1HRt21kQ5GmNMrOuupLBDVW+NWiR+E3FKCzHWY2pfFeRmUN5F6+cz7lrM7COHcdlJ4zjt6BEEksL1dm6MSSTdlRQS7wpRPAv2fgwHDu1vKF6Fa/yWkRLgJ+ceww1zJ7K56iBX/WEpp975Bg/8czP76pp8itQYEwu6Kyl4GTNhYCly6xW2vw+TvuBvLP2krd7gjoWlYZ8+uurT4/n72p08/M4WfvLSen7x6gYumF7EV08cy5EjsvwM3Rjjgy4fSY1VEXskFaCpHm4vhlnXwBk/jswxYtjqsn08/M7H/HVlBY0trcw5Ko/LZ4+l+kAjd766wR5pNSaOeX0k1ZJCqAdOh6RkuOKVyB0jxu060MCf3tvGo//aSmVNA0LnvtIzUgLcdt6nLDEYE0e8JoWB09tpfymeBeXLoDlxh8AcnpXGtz87gbd+cBpDMlMOGTyjrqmFny380JfYjDGRZUkhVPFMaGmAT1b7HYnvUpOTqK4NX/FcUV3Pj55fwwdb9xJvpU1jTNfitz+HSGmvbH4Piqb7G0sM6OqR1oyUJJ5Ysp1H3t1K8dAM5h1XwDlTCjlq5MBrwmJMIrGSQqicfBg8esC1VzhcXT3Sett5x7L0ptP5+ZePY9zwLO57YxNn3LWYuXcv5r43NlG2t7Z9/eeWlzP79kWMm/8Ss29fZONLGxPDIlrRLCJzgV/itI5+QFVv72K9C4CngONVtdta5IhXNAM8fSVsexe+ty6yx4kTzy0v7/KR1jZVNQ28vHoHz68oZ9k2Z9Cf48cOYcywQby4qoL6po7e1q2i2pjo8/3pIxEJABuAzwFlwBLgYlVdF7JeNvASzsA918ZEUnjv/+BvN8B318LgosgeawDatruWv66q4Lnl5XzUxcA/hbnpvD3fW1MYL0nJGNO9/uglta9mAhtVdbMb0BPAOUDoz+8fAz8DrotgLL1THFSvYEmh10YPy+Rbpx7JN085gvELXj7k6SWA8up6Tvv5GxTmZlA0JJOiIRkUDclonx+RnUZSkvDc8nIWPLuauqYWdzvr5dWYSIpkUigEtgfNlwGzglcQkalAsaq+KCJdJgURuRq4GmD06NERCDXEyGMgJRO2L4Fjzo/88QYoEemyojorLcDEkdmUV9extuIT9hzs/AhwSsDZ9pN99TQ0dx7oz3p5NSZyIpkUwvWd1P6j0R3i8y7gsp52pKr3A/eDc/uon+LrWiDFGaLTKpv77PozJ3b6pQ9tfS91rlOobWymfG8dZdV1lO2tc97vrWXr7tpwu6W8uo7rnlrJpPwcStxpcGZK2HXt9pMx3kUyKZQBxUHzRUBF0Hw2cAzwhogAjAJeEJF5PdUrREXxTHjnV9BUByk23vHh6qnvpTaZqclMGJnNhJBHWpdvWxS2pJGWnMQbpVU8/UFZ+7LC3AxKCnLaE8XkghyWfryHG/+yxm4/GeNRJJPCEmCCiIwDyoGLgK+0faiq+4DhbfMi8gZwXUwkBHCSQmszVCyHMSf5HU1cO3dq4WFfgLsqabQ9vVRZU8/6HTWsq9jPuh37WVexj9fW76TVLU+GdtEBHS2yLSkYc6iIJQVVbRaRa4GFOI+kPqiqa0XkVmCpqr4QqWP3i+BGbJYUfNNTSWNEdjojstP5zFF57dvUNbZQutNJFDf+JXzL9Irqes64601GDx3E2GGZjBmWyehhgxgzNJPCIRmkBDqa8NjtJ5NIrEO87twzHYZPhIv/FJ3jmX43+/bwt5+y0gKceMRwtu4+yLY9tZ3aUQSShMLcDMYMy6S1tZX3tuylubXje5KRksRt5x3rOTFYUjGxIBYeSY221ZZqAAAT90lEQVR/RTPho7+DqjMym4k7Xiq6VZXKmgY+3nWQrXtq2ba7lq17atm6+yCry/cR+ruprqmV7z25gt++uYnhWWkMy0pleFZa+/u8oGXvbNzFD59fa3UaJm5YUuhO8UxY+SfYsxmGHeF3NOYweKnoFhFG5qQzMiedWeOHddp+3PyXwu63VaF4aCa7DjSwddtBdh9opLaxJey6oeqaWrj5+TW0tCojctIYkZ3OyJw0BmekIF38+LDShokWSwrdKXabVZQtsaQQx/pS0d1VO4vC3Ax+99XOJfHaxmZ2H2ik6kADuw80sutAQ3upINT++ma+/9TKTstSk5PIy0pjRE4aI7PT3YSRRtneOp5dVk5ji3OLy0obJpIsKXQn72hIy3Eqm4+7yO9ojA+6uv10/ZkTD1k3MzWZzKHJFA/NbF/260UbwyaV/MHpPH7VCVTWNLBzfz2VNQ1U1tRTtb+BypoGNlUd4N3Nu7scM7uuqYUfPLOKD7bupXBIBgW5ba3BM8jLclqDB+trScPv7U30WFLoTlISFM1wxmw2CclrO4uudJVUfjD3aMYOH8TY4YO63b6+qYVJP3wlbFchDc2tvLCy4pDEkRpIIj83ncJcJ1nU1DWxqLSSphZnL+XVddzwzCo2VtYw56gRQEeVWVsq6biLJSzeUMVv39zU3rK8vLqO+c+uQlX50rSeu4Hpj65KLKlEjz191JM3boc3fwo/2ArpOdE7rhkw+npB6+oJqsLcDN6efxoHGpqpqK5rbxFevreO8uo6yvfWUlFdzyf76/vzn9NJbmYK2enJ5KQ7r9npHfM57vy9r2+kOkyJJ39wOm9cfwppyYEwe+4QmlSg9z3tWkknBnpJjZSoJ4WNr8Gj58Glz8ERp0bvuMa4+npRHDf/pbAlDYDHvj6r/ekqddfqmHd87cGuS8qXnjCGmvomauqb2e++tr0/0NB8yJNb4aQEhMzUZAalBhiUlkxmWjJZaQEyU5PJSktm4dpPwlbiDx2Uyt0XTiEzNUBGqrN+ZmrAnZIJuLfQ+nr+YiEp9Qd7JLW/FM0AxLmFZEnB+KCvt7C6qyyffeTwMFscul5X2//43GO63K61VTnQ2MznfvEmO/c3HPL54Ixkrp5zBAcamqltaOZgYwsH3dfahmZ2H6iltrGly6e69hxs5KvdJKzU5CQyUwPU1DXRcshjxU6dzAsrKwgkCclJQnIgieQkIZAkpATEXZ7E0x9s75QQ2ra/9a9rGTIotVMCy3QTW1pyUvuTZPF2+8ySQk/SB8OISVBm9QrGP5HoKiRcZXl/bp+UJOSkp7DgrElht//vecd4+jd1dftsRHYav/n3ae2Jo66p2Xnf4MzXNjVT19jCH97dGna/Dc2tVNU00NTSSkur0tKqNLW20tKiNLe6U0srBxq6SEq1TV2WopKTpD1BVNU0dGr8CE5Suem51WzZddBJJmkBBrklnSy3tDQoNUBmWjJvllZy64vr2htYRvrpM0sKXhTPhDV/gdZWp/LZmDjS15KG39t3lZRuPHsSM8YO7XH719ZXdlnS+et/ntzj9t0lpfsumcaBBreE0za5JZ7axhYONDR36rQx2IGGFn752kc9Hj+cSHYfb0nBi+JZ8MHDsGsDjDja72iM6bW+lDT83j5SSaWvJaUbz57E9DE9J6V3N+3uMiktvuFUahudBBKcSGobmznY0EJtYzM/eKar/rsO3Wd/sKTgRXDneJYUjIk6P5NKJJNSIEncJ7bCjwUC8KvXwrd1KciNTJf+lhR68tbdUDAVMoY6lc3TvwZbFkP5Mjj5O35HZ4zxIJFLOr1lSaEnhdPgqctg2JFOZfOWxc78lx/2OTBjTLzwM6n0lrVT8GLLYvjThdBUC0nJMOsaOGU+pGX3vK0xxsQAr+0U7FEaL8bNgRO+4bxPHwzv/hrunAjPXwtlS/HUQscYY+KAJQUvtix2nj6ac4Mzf9adcMyXYM0z8MBn4b6T4F/3Qe0eX8M0xpi+sqTQk+A6hNP+y3l98zY49kL4fil88ZeQkgGvzIefT4Snr4DNbzptGowxJs5YUuhJ+TInEYyb48yPm+PMly9zOsibfhlctQiueRumXw4b/wF/mAf3TIXFd8JrP3YSS7Ati52nmoyJB2/d3be/Yb+3N70S0aQgInNFpFRENorI/DCfXyMiq0VkhYi8JSIlkYznsJz8nY6E0GbcnEMfRx11DJz9M6f0cN4DMLgYFv0Y/vkLp0O9N++AluaOkkfhtKj9E+KaXVD6rq/noO0JvLZ99PZv2O/t/f4b8nv7XorY00ciEgA2AJ8DyoAlwMWqui5onRxV3e++nwd8U1XndrdfX54+Oly7N8HyR2HpQ1C/F5IzoLUZJp8LR38B8o+DIWMjO/7zW3c7X57gxNabdhZ+bx98+27cnEPnI7293//+/thH27953q+dHy+bXoe/3+RsO3g0NOyD+v3QsB8aajrety/bDwd3Q9NBSEpx/oYH5UHmUEjJdKcMd8qE1DDL9pU59XLj5sCWN2HqpZA7BlqboKURWprcqdHZf0ujO7nv91dAxQcw9AjYuwUmng0jJjtPAKbnOK9p2c6gWGlB8ykZ8PE//f0b8nt7l+9dZ4vIicAtqnqmO78AQFVv62L9i4GvqupZ3e03rpJCm5YmePYqWPsX58tUuwfUbYiSNhjyj4VRxzqv+cfBsAkQcJuQxPtFtbfbtzR3XJzapm3vOCWuMbNh61sw5RIYOg5aW5zz2P7aGjLfAtoKe7fBxr87HRtWroeSc5xR9douWslBF6+U9M7LdqyCF78DF/wejjgtOuevtaXzBXLLYieGubdD3kT4+C1njI8ZV0J2fseFu9PFvKbzssYDPcealOxcUNNzOi6u6UGvFSuh7D3In+Kcv6ZaaKpzp9qgyV3WeBC67LS7i+MHUiGQ4iSfQKrzPQikOvO1u+BglfP/pK3Q7GGciKRkJzkkpUDtbvf7twvyJkFWnnuclI7jdjp20Pz+Clj7LBRMc5LTUWdB1kg3cTU4/1/NDR3JrNld1tIAzY1QXw01OyA1GxprIGsUpA4CSQqZxHlNCnRe3rAfqkph0jwnqfYyIUBsJIULgLmq+nV3/lJglqpeG7Let4DvAanAaap6SA9RInI1cDXA6NGjp2/dGr7Xw5jVdiGYcSUs/T186X7nV9Ynq2DHSufCs3MtNLtN2ZPTYeRkJ0EkZ8CKR+H8B2HC6R37Ov/3UDCl48IZfCHo9FoDuz5yfi3lFMC+cufimJEb1HG+Ol8y1F0W8tqwH/Zshszh7hdqImQO6/hCJSV3TIEU5w86KaVjvmYHlL7i/Ht2rHAu7ikZQRf+oFibavt+viUJJOB+sdzX5gbnC5qU7FxoD2/HzjlJSoXkVHffbcdKDjpeyPGb66B6OwwaDgd3QXaBc7Fr/0Xs/kpu+9Wsh/GQQkpmxy/l9KBfy+k5zg+PtGynm5bNrztJcfplzvLgi35yetel1tC/YS8XJVXnvDfVwuY34MXvwrH/Bqufgi/+CsZ9uuOCH0jpvsQc7vjFJxz699M+H7qsxnl8fPdHkDvaub17SAmlqfN88P9JqEAaJKe5iSPN+XsIpIa8d6fkNOe16kOoXAcjSpxJW0Mm93uoLeE/27vFKXHNucF56KWXYiEpfBk4MyQpzFTV/+xi/a+463+tu/3GXUnB6y/FlmbnD3bHqs7JomFfxzrpg52LfyANWjz8SpKkjgtFUz3UVkFOofOFEAEk5JUulouTFPZucYr8g4udC1prk3thC33f3PEFa21x3jc3AOrEPigvTLE/pOgf/NnuTbDoJ3DcxbDqCZh3j5NYgi/67a9Jh15cQi8oFzzkdHLYVOv82mz/pVvf8Uu3uS7oV3AdlP7NKaUUzYLRM8OUSpq7KKm4JZiqD2HPJqdl/MhjOn6dtv86DvlVHO7Xa+nfoPQlZ7zwE77V+eIf6LrvnLDnoDe/NOOttNndPg7n36/qJLWnr4AZlzu3wXr7S70vx++P7fGeFFDViEzAicDCoPkFwIJu1k8C9vW03+nTp2tc+eddqpvf7Lxs85vO8p60tqru2aK69jnVB85Q/VGO6n0nq75yo+obP1V99zeqy/7ofL5xker2paqVpar7KlQbDjjbtx3vp+NUX/uJ8xoaT0/83L5t27ZtQucjvX1f4++P7fu6j76eg778DcfC9n7/Dfm9vQtYql6u3V5WOpwJp1+lzcA4nFtDK4HJIetMCHr/RS9Bx11S6A/xfFGN9wuS3//+/thHX89BvPP7b8jv7V2+JwUnBs7GeQJpE/Bf7rJbgXnu+18Ca4EVwOuhSSPclHBJwe8Lgt/b+y0W/v3xfg5NTPCaFMRZN37EXZ1CX/XHI43GmITntU7Bus6OdeEu/OPm9LqSyRhjvLBuLowxxrSzpGCMMaadJQVjjDHtLCkYY4xpZ0nBGGNMu7h7JFVEqoCuOj8aDuyKYji9ZfH1jcXXd7Eeo8XXN93FN0ZV83raQdwlhe6IyFIvz+H6xeLrG4uv72I9Rouvb/ojPrt9ZIwxpp0lBWOMMe0GWlK43+8AemDx9Y3F13exHqPF1zd9jm9A1SkYY4zpm4FWUjDGGNMHAyYpiMhcESkVkY0iMt/veEKJyMcislpEVoiI7928isiDIlIpImuClg0VkVdF5CP3dUiMxXeLiJS753CFiJztY3zFIvK6iKwXkbUi8v/c5TFxDruJLybOoYiki8j7IrLSje+/3eXjROQ99/z9WURSYyy+h0VkS9D5m+JHfEFxBkRkuYi86M73/fx56V871icggDNmw3g6BvQp8TuukBg/Bob7HUdQPHOAacCaoGU/A+a77+cDP42x+G4BrvP73Lmx5APT3PfZOOOGlMTKOewmvpg4hzgDXme571OA94ATgCeBi9zlvwW+EWPxPQxc4Pf5C4rze8CfgBfd+T6fv4FSUpgJbFTVzaraCDwBnONzTDFNVRcDe0IWnwM84r5/BDg3qkEF6SK+mKGqO1R1mfu+BlgPFBIj57Cb+GKCOg64synupMBpwNPucj/PX1fxxQwRKQI+Dzzgzgv9cP4GSlIoBLYHzZcRQ18AlwJ/F5EPRORqv4PpwkhV3QHORQUY4XM84VwrIqvc20u+3d4KJiJjgak4vyZj7hyGxAcxcg7dWx8rgErgVZzSfrWqNrur+Po9Do1PVdvO3/+45+8uEUnzKz7gbuAGoNWdH0Y/nL+BkhQkzLKYyurAbFWdBpwFfEtEbJSc3rsPOAKYAuwAfu5vOCAiWcAzwHdUdb/f8YQKE1/MnENVbVHVKUARTml/UrjVohtV0IFD4hORY4AFwNHA8cBQ4Ad+xCYiXwAqVfWD4MVhVu31+RsoSaEMKA6aLwIqfIolLFWtcF8rgb/gfAlizU4RyQdwXyt9jqcTVd3pflFbgd/h8zkUkRScC+5jqvqsuzhmzmG4+GLtHLoxVQNv4NyzzxWRthEhY+J7HBTfXPe2nKpqA/AQ/p2/2cA8EfkY53b5aTglhz6fv4GSFJYAE9ya91TgIuAFn2NqJyKDRCS77T1wBrCm+6188QLwNff914DnfYzlEG0XW9eX8PEcuvdvfw+sV9VfBH0UE+ewq/hi5RyKSJ6I5LrvM4DTceo9XgcucFfz8/yFi+/DoIQvOPfrfTl/qrpAVYtUdSzO9W6Rqv47/XH+/K4978da+LNxnrDYBPyX3/GExDYe54molcDaWIgPeBzn9kETTknrSpx7kq8BH7mvQ2Msvj8Cq4FVOBfffB/jOxmnaL4KWOFOZ8fKOewmvpg4h8CxwHI3jjXAze7y8cD7wEbgKSAtxuJb5J6/NcCjuE8o+TkBp9Dx9FGfz5+1aDbGGNNuoNw+MsYY0w8sKRhjjGlnScEYY0w7SwrGGGPaWVIwxhjTzpKCGZBEZGxwD6v9uN9bReT0Hta5RUSui1ZMxvSn5J5XMca0UdWb/Tq2iARUtcWv45vEYCUFM+CJyHi3z/njQ5afIiJviMjTIvKhiDzmtlRFRKaLyJtuB4YLg1qyPiwiF7jvz3a3e0tEftXWp72rxN33ZhH5dtDyZBF5xO1Q7WkRyXT39Vk3xtVuR3Vp7vKPReRmEXkL+LKIfFtE1rnbPxHB02YSlCUFM6CJyESc/n8uV9UlYVaZCnwHZ6yB8cBst8+ge3D6zZ8OPAj8T8h+04H/A85S1ZOBvJD9Hg2cidM3zo/cfQJMBO5X1WOB/cA33X09DFyoqp/CKcF/I2hf9ap6sqo+gTNGw1R3+2t6fUKM6YElBTOQ5eH0/XKJqq7oYp33VbVMnQ7iVgBjcS7cxwCvul0n34TTuViwo4HNqrrFnX885POXVLVBVXfhdIo30l2+XVXfdt8/itMdxURgi6pucJc/gjPIUJs/B71fBTwmIpcAzRjTz6xOwQxk+3DG2ZiN0+dUOA1B71twvhMCrFXVE7vZd7huinvaLxzalbF62NfBoPefx0kY84Afishk7eg/35g+s5KCGcgacXqy/KqIfKUX25UCeSJyIjhdUIvI5JB1PgTGuwPYAFzocd+j2/YLXAy85e5rrIgc6S6/FHgzdEMRSQKKVfV1nMFVcoEsj8c1xhMrKZgBTVUPugOSvCoiB1W1x66EVbXRrUz+lYgMxvme3E1QaUNV60Tkm8ArIrILp2dKL9YDXxOR/8PpSfU+Va0XkcuBp9y+8JfgjK8bKgA86sYkwF3q9PVvTL+xXlKNOUwikqWqB9wnlu4FPlLVu/yOy5i+sNtHxhy+q9yK6LXAYJynkYyJa1ZSMMYY085KCsYYY9pZUjDGGNPOkoIxxph2lhSMMca0s6RgjDGmnSUFY4wx7f4//RE6+6pPqvwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.581886278515492,\n",
       " 0.32811258653955283,\n",
       " 0.30575417092271023,\n",
       " 0.2947452048575644,\n",
       " 0.2979230507320395,\n",
       " 0.2981500397230734,\n",
       " 0.29712858926342073,\n",
       " 0.3003064351378958,\n",
       " 0.3009874021109976,\n",
       " 0.29883100669617524,\n",
       " 0.2981500397230734,\n",
       " 0.29939847917376006,\n",
       " 0.3026898195437521,\n",
       " 0.3059811599137442,\n",
       " 0.3037112700034048,\n",
       " 0.30495970945409145,\n",
       " 0.3017818635796164,\n",
       " 0.30053342412892975,\n",
       " 0.3020088525706503,\n",
       " 0.30155487458858243]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "differences = []\n",
    "for k in range(1, 40, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    difference = knn.score(X_train, y_train) - knn.score(X_test, y_test)\n",
    "    differences.append(difference)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}/{difference:.3f}\")\n",
    "    \n",
    "# consistency     \n",
    "# for x in differences:\n",
    "#     consistent = (x + 1) - x \n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_scores\n",
    "test_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data for better fit perhaps?\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.610/0.390\n",
      "k: 3, Train/Test Score: 0.725/0.375/0.351\n",
      "k: 5, Train/Test Score: 0.587/0.358/0.229\n",
      "k: 7, Train/Test Score: 0.527/0.359/0.168\n",
      "k: 9, Train/Test Score: 0.491/0.350/0.140\n",
      "k: 11, Train/Test Score: 0.472/0.344/0.127\n",
      "k: 13, Train/Test Score: 0.456/0.342/0.114\n",
      "k: 15, Train/Test Score: 0.449/0.344/0.104\n",
      "k: 17, Train/Test Score: 0.442/0.349/0.093\n",
      "k: 19, Train/Test Score: 0.435/0.350/0.085\n",
      "k: 21, Train/Test Score: 0.428/0.349/0.079\n",
      "k: 23, Train/Test Score: 0.425/0.352/0.073\n",
      "k: 25, Train/Test Score: 0.420/0.353/0.067\n",
      "k: 27, Train/Test Score: 0.415/0.355/0.060\n",
      "k: 29, Train/Test Score: 0.412/0.354/0.058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-86b54208969e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdifferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}/{difference:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "differences = []\n",
    "for k in range(1, 40, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    difference = knn.score(X_train, y_train) - knn.score(X_test, y_test)\n",
    "    differences.append(difference)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}/{difference:.3f}\")\n",
    "    \n",
    "# consistency     \n",
    "# for x in differences:\n",
    "#     consistent = (x + 1) - x \n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned up dataset\n",
    "df_cleaned = df[[\"highest_tier\",\"wardsKilled\",\n",
    "                 \"creeps_early\",\n",
    "                 \"gold_early\",\"creeps_mid\",\"visionScore\",\n",
    "                 \"longestTimeSpentLiving\",\"totalDamageDealtToChampions\",\"totalMinionsKilled\",\n",
    "                 \"dmgtaken_early\",\"timeCCingOthers\",\"csdiff_early\",\"xp_end\",\"goldSpent\",\"kills\",\"totalDamageTaken\",\n",
    "                 \"xp_mid\",\"champLevel\",\"xp_early\",\"gold_mid\",\"damageSelfMitigated\",\"goldEarned\",\"dmgtaken_diff_mid\",\"creeps_end\",\"csdiff_mid\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the data targets etc\n",
    "\n",
    "# defining the target\n",
    "\n",
    "target = df[\"highest_tier\"]\n",
    "data = df.drop(\"highest_tier\", axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()\n",
    "\n",
    "# train the model using the meaning of life\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "differences = []\n",
    "for k in range(1, 40, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    difference = knn.score(X_train, y_train) - knn.score(X_test, y_test)\n",
    "    differences.append(difference)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}/{difference:.3f}\")\n",
    "    \n",
    "# consistency     \n",
    "# for x in differences:\n",
    "#     consistent = (x + 1) - x \n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to determine the best K for this dataset\n",
    "chosenk = 33\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=chosenk)\n",
    "knn.fit(X_train, y_train)\n",
    "print(f'k={chosenk} Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle \n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "\n",
    "filename = 'pickledModel.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(knn,outfile)\n",
    "outfile.close()\n",
    "\n",
    "######## START HERE ######### review this!!\n",
    "\n",
    "# saved_model = pickle.dumps(knn) \n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
